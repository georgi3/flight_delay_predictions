{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [],
   "source": [
    "import datetime, warnings, scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, linear_model\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from scipy.optimize import curve_fit\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [],
   "source": [
    "def reload_file(fname):\n",
    "    return pd.read_csv(fname)\n",
    "\n",
    "\n",
    "fn_flight = '../data/flight_data.csv'\n",
    "fn_passenger = '../data/passengers_sample.csv'\n",
    "fn_fuel = '../data/fuel_consumption.csv'\n",
    "fn_jan_flights = '../data/january_flights.csv'\n",
    "fn_test_flights = '../data/test_flights.csv'\n",
    "fn_semi_test = '../data/tester_flights.csv'\n",
    "flight_df = pd.read_csv(fn_flight)\n",
    "passenger_df = pd.read_csv(fn_passenger)\n",
    "fuel_df = pd.read_csv(fn_fuel)\n",
    "jan_flights = pd.read_csv(fn_jan_flights)\n",
    "test_flights = pd.read_csv(fn_test_flights)\n",
    "semi_test = pd.read_csv(fn_semi_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [],
   "source": [
    "def parse_dates(df):\n",
    "    \"\"\"Takes string date parses to pd.datetime object\"\"\"\n",
    "    try:\n",
    "        df['fl_date'] = pd.to_datetime(df['fl_date'])\n",
    "    except KeyError as err:\n",
    "        print('Unsuccessful parsing...')\n",
    "        raise KeyError(f'passed DataFrame does not have key {err}')\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_time(series):\n",
    "    \"\"\"Formats time\"\"\"\n",
    "    if pd.isnull(series):\n",
    "        return np.nan\n",
    "    else:\n",
    "        if series == 2400:\n",
    "            series = 0\n",
    "        series = f\"{int(series):04d}\"\n",
    "        hour = datetime.time(int(series[0:2]), int(series[2:4]))\n",
    "        return hour\n",
    "\n",
    "\n",
    "def combine_date_time(x):\n",
    "    \"\"\"Produces datetime.datetime object\"\"\"\n",
    "    if pd.isnull(x[0]) or pd.isnull(x[1]):\n",
    "        return pd.nan\n",
    "    else:\n",
    "        return datetime.datetime.combine(x[0], x[1])\n",
    "\n",
    "\n",
    "# TODO look over to try avoid looping\n",
    "def create_date_time(df, feature):\n",
    "    lst = []\n",
    "    for index, cols in df[['fl_date', feature]].iterrows():\n",
    "        if pd.isnull(cols[1]):\n",
    "            lst.append(np.nan)\n",
    "        elif float(cols[1]) == 2400:\n",
    "            cols[0] += datetime.timedelta(days=1)\n",
    "            cols[1] = datetime.time(0,0)\n",
    "            lst.append(combine_date_time(cols))\n",
    "        else:\n",
    "            cols[1] = format_time(cols[1])\n",
    "            lst.append(combine_date_time(cols))\n",
    "    return pd.Series(lst)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "def get_stats(group):\n",
    "    return {'min': group.min(), 'max': group.max(),\n",
    "            'count': group.count(), 'mean': group.mean()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "def get_flight_delays(df, airline, airport_id, extreme_values = False):\n",
    "    df2 = df[(df['airline'] == airline) & (df['origin'] == airport_id)]\n",
    "    # remove extreme values before fitting\n",
    "    if extreme_values:\n",
    "        df2['arr_delay'] = df2['arr_delay'].apply(lambda x: x if x < 60 else np.nan)\n",
    "        df2.dropna(axis=0, inplace=True)\n",
    "    # Conversion: datetime to time\n",
    "    df2.sort_values('scheduled_dep', inplace = True)\n",
    "    df2['departing_hour'] =  df2['scheduled_dep'].apply(lambda x:x.time())\n",
    "    # grouping by time and calculating mean\n",
    "    # print(airline, airport_id, 'right before unstacking')\n",
    "    test2 = df2['arr_delay'].groupby(df2['departing_hour']).apply(get_stats).unstack()\n",
    "    test2.reset_index(inplace=True)\n",
    "    # converting time to seconds\n",
    "    fct = lambda x:x.hour*3600+x.minute*60+x.second\n",
    "    test2.reset_index(inplace=True)\n",
    "    test2['departing_in_sec'] = test2['departing_hour'].apply(fct)\n",
    "    return test2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "def get_merged_delays(df, carrier):\n",
    "    airports = df[df['airline'] == carrier]['origin'].unique()\n",
    "    i = 0\n",
    "    columns = ['origin', 'departing_in_sec', 'mean']\n",
    "    for airport in airports:\n",
    "        # ********************** SPECIAL CASE **************\n",
    "        if (airport == 'MMH' and carrier == 'AS') or (airport=='LIT' and\n",
    "        carrier == 'G4') or (airport=='ROA' and carrier == 'G4') or (airport=='SWF' and carrier == 'G4'):\n",
    "            print('continue')\n",
    "            continue\n",
    "        # ************************************************\n",
    "        df2 = get_flight_delays(df, carrier, airport, True)\n",
    "        # **********************\n",
    "        df2.loc[:, 'origin'] = airport\n",
    "        df2 = df2[columns]\n",
    "        df2.dropna(axis=0, inplace=True)\n",
    "        if i == 0:\n",
    "            merged_df = df2.copy()\n",
    "        else:\n",
    "            merged_df = pd.concat([merged_df, df2], ignore_index=True)\n",
    "        i += 1\n",
    "    return merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "outputs": [],
   "source": [
    "def test_datasets_preparation(data):\n",
    "    data = parse_dates(data)\n",
    "    data['crs_dep_datetime'] = create_date_time(data, 'crs_dep_time')\n",
    "    data['crs_dep_time'] = data['crs_dep_time'].apply(format_time)\n",
    "    data['airline'] = data['mkt_unique_carrier']\n",
    "    data = data[['crs_dep_datetime','airline','mkt_carrier_fl_num', 'origin','dest', 'crs_arr_time','crs_elapsed_time','distance']]\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "def datasets_preparation(data):\n",
    "    data = parse_dates(data)\n",
    "    data['crs_dep_datetime'] = create_date_time(data, 'crs_dep_time')\n",
    "    data['crs_dep_time'] = data['crs_dep_time'].apply(format_time)\n",
    "    data['crs_arr_time'] = data['crs_arr_time'].apply(format_time)\n",
    "    data['arr_time'] = data['arr_time'].apply(format_time)\n",
    "\n",
    "    data['airline'] = data['mkt_unique_carrier']\n",
    "    data['scheduled_dep'] = data['crs_dep_datetime']\n",
    "\n",
    "    data = data[['airline','tail_num','origin','dest', 'crs_dep_datetime','dep_delay', 'arr_delay', 'crs_arr_time','taxi_out','taxi_in','scheduled_dep','crs_elapsed_time','air_time','distance']]\n",
    "    # data = data.dropna(inplace=True, axis=0)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "def splitting_data(data, airlines):\n",
    "    data = data[data[[*data.columns.tolist()]].notna()]\n",
    "    datasets = {}\n",
    "    i = 0\n",
    "    for airline in airlines:\n",
    "        i += 1\n",
    "        # **********************\n",
    "        merged_df = get_merged_delays(data, airline)\n",
    "        # **********************\n",
    "        merged_df = pd.get_dummies(merged_df, ['origin'])\n",
    "        # –––––––––––––––––––––COLS TO KEEP––––––––––––––––––\n",
    "        merged_df['distance'] = data['distance']\n",
    "        merged_df['crs_elapsed_time'] = data['crs_elapsed_time']\n",
    "        # –––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "        x_not_scaled = merged_df.drop(['mean'], axis=1)\n",
    "        y = merged_df['mean']\n",
    "        # ––––––––––––––––––––––––Scaling–––––––––––––––––––––\n",
    "        # x_scaled = scaler(x_not_scaled)\n",
    "        # X = pd.DataFrame(x_scaled, columns=x_not_scaled.columns)\n",
    "        # –––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "        datasets[airline] = (x_not_scaled, y)\n",
    "        print(f'Dataset for {airline} is ready: {i}/{len(airlines)}')\n",
    "    data_records = {al:dfs[0].columns.tolist() for al, dfs in datasets.items()}\n",
    "    with open('../data/data_records.json', 'w') as fp:\n",
    "            json.dump(data_records, fp)\n",
    "    return datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "def splitting_test_data(data, airlines):\n",
    "    data = data[data[[*data.columns.tolist()]].notna()]\n",
    "    # data = data.dropna(inplace=True, axis=0)\n",
    "    datasets = {}\n",
    "    i = 0\n",
    "    for airline in airlines:\n",
    "        i += 1\n",
    "        # **********************\n",
    "        merged_df = get_merged_delays(data, airline)\n",
    "        # **********************\n",
    "        merged_df = pd.get_dummies(merged_df, ['origin'])\n",
    "        # –––––––––––––––––––––COLS TO KEEP––––––––––––––––––\n",
    "        merged_df['distance'] = data['distance']\n",
    "        merged_df['crs_elapsed_time'] = data['crs_elapsed_time']\n",
    "        # –––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "        x_not_scaled = merged_df.drop(['mean'], axis=1)\n",
    "        y = merged_df['mean']\n",
    "        datasets[airline] = (x_not_scaled, y)\n",
    "        print(f'Dataset for {airline} is ready: {i}/{len(airlines)}')\n",
    "    return datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "def scaler(df):\n",
    "    scaler_ = MinMaxScaler()\n",
    "    scaled = scaler_.fit_transform(df)\n",
    "    return scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "outputs": [],
   "source": [
    "def trainer(datasets, airlines):\n",
    "    models = {}\n",
    "    for airline in airlines:\n",
    "        x, y = datasets[airline]\n",
    "        ## –––––––––––XGB–––––––––––\n",
    "        # xg_reg = xgb.XGBRegressor(objective='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "        #                           max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "        # model = xg_reg.fit(x, y)\n",
    "        # model_name = 'xgb'\n",
    "        ## –––––––––––––––––––––––––\n",
    "        # print(id(xg_reg))\n",
    "        ## –––––––Linear Regressor––––––\n",
    "        # regressor = linear_model.LinearRegression()\n",
    "        # model = regressor.fit(x, y)\n",
    "        # model_name = 'lin_reg'\n",
    "        ## –––––––––––––––––––––––––\n",
    "        # –––––––Random Forest Regressor––––––\n",
    "        regressor = RandomForestRegressor()\n",
    "        model = regressor.fit(x, y)\n",
    "        model_name = 'rfr'\n",
    "        # –––––––––––––––––––––––––\n",
    "        # –––––––Random Forest Regressor––––––\n",
    "        # regressor = SVR(kernel='poly')\n",
    "        # model = regressor.fit(x, y)\n",
    "        # model_name = 'svr'\n",
    "        # –––––––––––––––––––––––––\n",
    "\n",
    "\n",
    "\n",
    "        fn_name = '../data/' + airline + f'_{model_name}.sav'\n",
    "        pickle.dump(model, open(fn_name, 'wb'))\n",
    "        models[airline] = fn_name\n",
    "        print(f'Model for airline {airline} is built.')\n",
    "    return models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [],
   "source": [
    "def pre_populate(data_predict, airlines):\n",
    "    \"\"\"Assuming Init Model seen all the columns\"\"\"\n",
    "    with open('../data/data_records.json') as f:\n",
    "        records = json.load(f)\n",
    "    dict_df = {}\n",
    "    for airline in airlines:\n",
    "        x_cur, y = data_predict[airline]\n",
    "        init_col = records[airline]\n",
    "        curr_cols = x_cur.columns.to_list()\n",
    "        missing_cols = set(init_col) - set(curr_cols)\n",
    "        for col in missing_cols:\n",
    "            x_cur[col] = 0\n",
    "        x = x_cur.reindex(columns=init_col)\n",
    "        dict_df[airline] = x, y\n",
    "    return dict_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [],
   "source": [
    "def eval(models, data):\n",
    "    results = {}\n",
    "    for dataset in data:\n",
    "        airline, x, y, = dataset\n",
    "        model = models[airline]\n",
    "        y_pred = model.predict(x)\n",
    "        mse = f\"MSE ={metrics.mean_squared_error(y_pred, y)}\"\n",
    "        mae = f\"MAE ={metrics.mean_absolute_error(y_pred, y)}\"\n",
    "        r2 = f\"R^2 ={metrics.r2_score(y_pred, y)}\"\n",
    "        results[airline] = (mse, mae, r2)\n",
    "        print(mse)\n",
    "        print(mae)\n",
    "        print(r2)\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [],
   "source": [
    "training_data = reload_file(fn_semi_test)\n",
    "semi_test = reload_file(fn_flight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [],
   "source": [
    "airlines = training_data['mkt_unique_carrier'].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "training_datasets = datasets_preparation(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "outputs": [
    {
     "data": {
      "text/plain": "       airline tail_num origin dest    crs_dep_datetime  dep_delay  arr_delay  \\\n0           HA   N488HA    HNL  ITO 2018-01-01 06:00:00      -10.0        2.0   \n1           NK   N603NK    BWI  RSW 2018-01-01 09:00:00       -4.0       -7.0   \n2           NK   N622NK    RSW  BWI 2018-01-01 19:44:00       18.0        2.0   \n3           NK   N633NK    ACY  MYR 2018-01-01 07:15:00       -6.0       -9.0   \n4           NK   N669NK    FLL  DTW 2018-01-01 20:30:00       -5.0        0.0   \n...        ...      ...    ...  ...                 ...        ...        ...   \n634726      DL   N557NW    MCO  ATL 2019-07-31 07:45:00       -2.0       -5.0   \n634727      DL   N382DN    ATL  LGA 2019-07-31 21:30:00        NaN        NaN   \n634728      DL   N925DN    ATL  IAH 2019-07-31 15:46:00       -1.0      -23.0   \n634729      DL   N925DN    IAH  ATL 2019-07-31 17:49:00       46.0       35.0   \n634730      DL   N940AT    LGA  ORD 2019-07-31 11:10:00       42.0       18.0   \n\n       crs_arr_time  taxi_out  taxi_in       scheduled_dep  crs_elapsed_time  \\\n0          06:53:00      21.0      7.0 2018-01-01 06:00:00              53.0   \n1          11:40:00      12.0      3.0 2018-01-01 09:00:00             160.0   \n2          22:07:00      10.0      5.0 2018-01-01 19:44:00             143.0   \n3          08:48:00       9.0      3.0 2018-01-01 07:15:00              93.0   \n4          23:28:00      24.0     11.0 2018-01-01 20:30:00             178.0   \n...             ...       ...      ...                 ...               ...   \n634726     09:23:00      22.0     14.0 2019-07-31 07:45:00              98.0   \n634727     23:50:00       NaN      NaN 2019-07-31 21:30:00             140.0   \n634728     17:05:00      12.0      9.0 2019-07-31 15:46:00             139.0   \n634729     21:02:00      14.0     11.0 2019-07-31 17:49:00             133.0   \n634730     12:56:00      18.0     11.0 2019-07-31 11:10:00             166.0   \n\n        air_time  distance  \n0           37.0     216.0  \n1          142.0     919.0  \n2          112.0     919.0  \n3           78.0     466.0  \n4          148.0    1127.0  \n...          ...       ...  \n634726      59.0     404.0  \n634727       NaN     762.0  \n634728      96.0     689.0  \n634729      97.0     689.0  \n634730     113.0     733.0  \n\n[634731 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>airline</th>\n      <th>tail_num</th>\n      <th>origin</th>\n      <th>dest</th>\n      <th>crs_dep_datetime</th>\n      <th>dep_delay</th>\n      <th>arr_delay</th>\n      <th>crs_arr_time</th>\n      <th>taxi_out</th>\n      <th>taxi_in</th>\n      <th>scheduled_dep</th>\n      <th>crs_elapsed_time</th>\n      <th>air_time</th>\n      <th>distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HA</td>\n      <td>N488HA</td>\n      <td>HNL</td>\n      <td>ITO</td>\n      <td>2018-01-01 06:00:00</td>\n      <td>-10.0</td>\n      <td>2.0</td>\n      <td>06:53:00</td>\n      <td>21.0</td>\n      <td>7.0</td>\n      <td>2018-01-01 06:00:00</td>\n      <td>53.0</td>\n      <td>37.0</td>\n      <td>216.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NK</td>\n      <td>N603NK</td>\n      <td>BWI</td>\n      <td>RSW</td>\n      <td>2018-01-01 09:00:00</td>\n      <td>-4.0</td>\n      <td>-7.0</td>\n      <td>11:40:00</td>\n      <td>12.0</td>\n      <td>3.0</td>\n      <td>2018-01-01 09:00:00</td>\n      <td>160.0</td>\n      <td>142.0</td>\n      <td>919.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NK</td>\n      <td>N622NK</td>\n      <td>RSW</td>\n      <td>BWI</td>\n      <td>2018-01-01 19:44:00</td>\n      <td>18.0</td>\n      <td>2.0</td>\n      <td>22:07:00</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>2018-01-01 19:44:00</td>\n      <td>143.0</td>\n      <td>112.0</td>\n      <td>919.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NK</td>\n      <td>N633NK</td>\n      <td>ACY</td>\n      <td>MYR</td>\n      <td>2018-01-01 07:15:00</td>\n      <td>-6.0</td>\n      <td>-9.0</td>\n      <td>08:48:00</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>2018-01-01 07:15:00</td>\n      <td>93.0</td>\n      <td>78.0</td>\n      <td>466.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NK</td>\n      <td>N669NK</td>\n      <td>FLL</td>\n      <td>DTW</td>\n      <td>2018-01-01 20:30:00</td>\n      <td>-5.0</td>\n      <td>0.0</td>\n      <td>23:28:00</td>\n      <td>24.0</td>\n      <td>11.0</td>\n      <td>2018-01-01 20:30:00</td>\n      <td>178.0</td>\n      <td>148.0</td>\n      <td>1127.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>634726</th>\n      <td>DL</td>\n      <td>N557NW</td>\n      <td>MCO</td>\n      <td>ATL</td>\n      <td>2019-07-31 07:45:00</td>\n      <td>-2.0</td>\n      <td>-5.0</td>\n      <td>09:23:00</td>\n      <td>22.0</td>\n      <td>14.0</td>\n      <td>2019-07-31 07:45:00</td>\n      <td>98.0</td>\n      <td>59.0</td>\n      <td>404.0</td>\n    </tr>\n    <tr>\n      <th>634727</th>\n      <td>DL</td>\n      <td>N382DN</td>\n      <td>ATL</td>\n      <td>LGA</td>\n      <td>2019-07-31 21:30:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23:50:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2019-07-31 21:30:00</td>\n      <td>140.0</td>\n      <td>NaN</td>\n      <td>762.0</td>\n    </tr>\n    <tr>\n      <th>634728</th>\n      <td>DL</td>\n      <td>N925DN</td>\n      <td>ATL</td>\n      <td>IAH</td>\n      <td>2019-07-31 15:46:00</td>\n      <td>-1.0</td>\n      <td>-23.0</td>\n      <td>17:05:00</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>2019-07-31 15:46:00</td>\n      <td>139.0</td>\n      <td>96.0</td>\n      <td>689.0</td>\n    </tr>\n    <tr>\n      <th>634729</th>\n      <td>DL</td>\n      <td>N925DN</td>\n      <td>IAH</td>\n      <td>ATL</td>\n      <td>2019-07-31 17:49:00</td>\n      <td>46.0</td>\n      <td>35.0</td>\n      <td>21:02:00</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>2019-07-31 17:49:00</td>\n      <td>133.0</td>\n      <td>97.0</td>\n      <td>689.0</td>\n    </tr>\n    <tr>\n      <th>634730</th>\n      <td>DL</td>\n      <td>N940AT</td>\n      <td>LGA</td>\n      <td>ORD</td>\n      <td>2019-07-31 11:10:00</td>\n      <td>42.0</td>\n      <td>18.0</td>\n      <td>12:56:00</td>\n      <td>18.0</td>\n      <td>11.0</td>\n      <td>2019-07-31 11:10:00</td>\n      <td>166.0</td>\n      <td>113.0</td>\n      <td>733.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>634731 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for HA is ready: 1/11\n",
      "Dataset for NK is ready: 2/11\n",
      "Dataset for AA is ready: 3/11\n",
      "Dataset for UA is ready: 4/11\n",
      "continue\n",
      "Dataset for AS is ready: 5/11\n",
      "Dataset for DL is ready: 6/11\n",
      "continue\n",
      "continue\n",
      "continue\n",
      "Dataset for G4 is ready: 7/11\n",
      "Dataset for WN is ready: 8/11\n",
      "Dataset for VX is ready: 9/11\n",
      "Dataset for B6 is ready: 10/11\n",
      "Dataset for F9 is ready: 11/11\n"
     ]
    }
   ],
   "source": [
    "split_data_train = splitting_data(training_datasets, airlines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for airline WN is built.\n",
      "Model for airline AA is built.\n",
      "Model for airline UA is built.\n",
      "Model for airline HA is built.\n",
      "Model for airline AS is built.\n",
      "Model for airline NK is built.\n",
      "Model for airline DL is built.\n",
      "Model for airline B6 is built.\n",
      "Model for airline F9 is built.\n",
      "Model for airline G4 is built.\n"
     ]
    }
   ],
   "source": [
    "models = trainer(split_data_train, airlines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [],
   "source": [
    "airlines1 = semi_test['mkt_unique_carrier'].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [],
   "source": [
    "ready_to_test = datasets_preparation(semi_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for UA is ready: 1/11\n",
      "Dataset for AA is ready: 2/11\n",
      "Dataset for DL is ready: 3/11\n",
      "Dataset for F9 is ready: 4/11\n",
      "Dataset for NK is ready: 5/11\n",
      "Dataset for VX is ready: 6/11\n",
      "Dataset for WN is ready: 7/11\n",
      "continue\n",
      "Dataset for AS is ready: 8/11\n",
      "continue\n",
      "continue\n",
      "continue\n",
      "Dataset for G4 is ready: 9/11\n",
      "Dataset for B6 is ready: 10/11\n",
      "Dataset for HA is ready: 11/11\n"
     ]
    }
   ],
   "source": [
    "split_test_data = splitting_test_data(ready_to_test, airlines1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "data_to_test = pre_populate(split_test_data, airlines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [],
   "source": [
    "def get_results(model_name):\n",
    "    print(f'–––––––––––––––––––{model_name} Predictions–––––––––––––––––––––')\n",
    "    for airline in airlines:\n",
    "        # load the model from disk\n",
    "        print(airline)\n",
    "        loaded_model = pickle.load(open(models[airline], 'rb'))\n",
    "        X_test, y_test = data_to_test[airline]\n",
    "        y_pred = loaded_model.predict(X_test)\n",
    "        mse = f\"MSE = {metrics.mean_squared_error(y_pred, y_test)}\"\n",
    "        mae = f\"MAE = {metrics.mean_absolute_error(y_pred, y_test)}\"\n",
    "        r2 = f\"R^2 = {metrics.r2_score(y_pred, y_test)}\"\n",
    "        print(f'******Results for {airline}*************')\n",
    "        print(mse)\n",
    "        print(mae)\n",
    "        print(r2)\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–––––––––––––––––––XGBOOST Predictions–––––––––––––––––––––\n",
      "HA\n",
      "******Results for HA*************\n",
      "MSE = 121.2604418537729\n",
      "MAE = 7.711917607137268\n",
      "R^2 = -173.68141211772414\n",
      "\n",
      "NK\n",
      "******Results for NK*************\n",
      "MSE = 263.5446634506673\n",
      "MAE = 12.465441057393608\n",
      "R^2 = -617.7390787818701\n",
      "\n",
      "AA\n",
      "******Results for AA*************\n",
      "MSE = 256.1402648369833\n",
      "MAE = 12.118718660841614\n",
      "R^2 = -263.412991171914\n",
      "\n",
      "UA\n",
      "******Results for UA*************\n",
      "MSE = 267.47374070554406\n",
      "MAE = 12.39639967671234\n",
      "R^2 = -558.1640168307237\n",
      "\n",
      "AS\n",
      "******Results for AS*************\n",
      "MSE = 249.071197294509\n",
      "MAE = 11.746317104683705\n",
      "R^2 = -502.25796664921876\n",
      "\n",
      "DL\n",
      "******Results for DL*************\n",
      "MSE = 232.66065229361698\n",
      "MAE = 11.523182551207887\n",
      "R^2 = -658.5775200678738\n",
      "\n",
      "G4\n",
      "******Results for G4*************\n",
      "MSE = 318.1452921698196\n",
      "MAE = 13.596668880857793\n",
      "R^2 = -353.9382280572989\n",
      "\n",
      "WN\n",
      "******Results for WN*************\n",
      "MSE = 188.27708442290654\n",
      "MAE = 10.16939949420154\n",
      "R^2 = -110.88272807160696\n",
      "\n",
      "VX\n",
      "******Results for VX*************\n",
      "MSE = 420.7049045073321\n",
      "MAE = 15.57457243595072\n",
      "R^2 = -110.93440881592446\n",
      "\n",
      "B6\n",
      "******Results for B6*************\n",
      "MSE = 376.50779981161594\n",
      "MAE = 15.141746521087187\n",
      "R^2 = -480.5004701657015\n",
      "\n",
      "F9\n",
      "******Results for F9*************\n",
      "MSE = 427.444006860865\n",
      "MAE = 16.389763856600972\n",
      "R^2 = -551.7534170965388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn_models_xgb = {'HA': '../data/HA_xgb.sav',\n",
    "                 'NK': '../data/NK_xgb.sav',\n",
    "                 'AA': '../data/AA_xgb.sav',\n",
    "                 'UA': '../data/UA_xgb.sav',\n",
    "                 'AS': '../data/AS_xgb.sav',\n",
    "                 'DL': '../data/DL_xgb.sav',\n",
    "                 'G4': '../data/G4_xgb.sav',\n",
    "                 'WN': '../data/WN_xgb.sav',\n",
    "                 'VX': '../data/VX_xgb.sav',\n",
    "                 'B6': '../data/B6_xgb.sav',\n",
    "                 'F9': '../data/F9_xgb.sav'}\n",
    "get_results('XGBOOST')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–––––––––––––––––––Linear Regression Predictions–––––––––––––––––––––\n",
      "HA\n",
      "******Results for HA*************\n",
      "MSE = 123.26087156722743\n",
      "MAE = 7.6861741912891555\n",
      "R^2 = -29.614281251741385\n",
      "\n",
      "NK\n",
      "******Results for NK*************\n",
      "MSE = 253.82190268346915\n",
      "MAE = 11.857093081170477\n",
      "R^2 = -27.252596399737612\n",
      "\n",
      "AA\n",
      "******Results for AA*************\n",
      "MSE = 250.64809324903598\n",
      "MAE = 11.790800602659244\n",
      "R^2 = -24.30962120783478\n",
      "\n",
      "UA\n",
      "******Results for UA*************\n",
      "MSE = 263.43685441800994\n",
      "MAE = 12.044446996778946\n",
      "R^2 = -42.08931641366809\n",
      "\n",
      "AS\n",
      "******Results for AS*************\n",
      "MSE = 239.9488890764281\n",
      "MAE = 11.355106098107585\n",
      "R^2 = -19.70089482780543\n",
      "\n",
      "DL\n",
      "******Results for DL*************\n",
      "MSE = 224.42657686423985\n",
      "MAE = 10.884630870070565\n",
      "R^2 = -39.47352861581824\n",
      "\n",
      "G4\n",
      "******Results for G4*************\n",
      "MSE = 316.67167087707816\n",
      "MAE = 13.30118482211203\n",
      "R^2 = -14.904447145538839\n",
      "\n",
      "WN\n",
      "******Results for WN*************\n",
      "MSE = 181.39307783840428\n",
      "MAE = 9.740823128131675\n",
      "R^2 = -10.05528115097552\n",
      "\n",
      "VX\n",
      "******Results for VX*************\n",
      "MSE = 471.0168300968559\n",
      "MAE = 16.512157164580078\n",
      "R^2 = -13.996439233895298\n",
      "\n",
      "B6\n",
      "******Results for B6*************\n",
      "MSE = 369.7362624867735\n",
      "MAE = 14.737604237241467\n",
      "R^2 = -25.43078918320344\n",
      "\n",
      "F9\n",
      "******Results for F9*************\n",
      "MSE = 435.164727624387\n",
      "MAE = 16.34552425248821\n",
      "R^2 = -23.19643950664465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn_models_lin_reg = {'HA': '../data/HA_linreg.sav',\n",
    "                     'NK': '../data/NK_linreg.sav',\n",
    "                     'AA': '../data/AA_linreg.sav',\n",
    "                     'UA': '../data/UA_linreg.sav',\n",
    "                     'AS': '../data/AS_linreg.sav',\n",
    "                     'DL': '../data/DL_linreg.sav',\n",
    "                     'G4': '../data/G4_linreg.sav',\n",
    "                     'WN': '../data/WN_linreg.sav',\n",
    "                     'VX': '../data/VX_linreg.sav',\n",
    "                     'B6': '../data/B6_linreg.sav',\n",
    "                     'F9': '../data/F9_linreg.sav'}\n",
    "get_results('Linear Regression')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–––––––––––––––––––RandomForestRegressor Predictions–––––––––––––––––––––\n",
      "HA\n",
      "******Results for HA*************\n",
      "MSE = 117.7230412596377\n",
      "MAE = 7.592602332653435\n",
      "R^2 = -6.104765575621075\n",
      "\n",
      "NK\n",
      "******Results for NK*************\n",
      "MSE = 266.76821254955627\n",
      "MAE = 12.16856601040853\n",
      "R^2 = -10.110609911012263\n",
      "\n",
      "AA\n",
      "******Results for AA*************\n",
      "MSE = 264.33372027721435\n",
      "MAE = 12.09297147036694\n",
      "R^2 = -8.476420273203363\n",
      "\n",
      "UA\n",
      "******Results for UA*************\n",
      "MSE = 277.66267153479276\n",
      "MAE = 12.329773262676559\n",
      "R^2 = -9.632467330630528\n",
      "\n",
      "AS\n",
      "******Results for AS*************\n",
      "MSE = 241.87565551362812\n",
      "MAE = 11.486633735119955\n",
      "R^2 = -7.793706074571061\n",
      "\n",
      "DL\n",
      "******Results for DL*************\n",
      "MSE = 238.163953008909\n",
      "MAE = 11.262200596941746\n",
      "R^2 = -10.807232721598112\n",
      "\n",
      "G4\n",
      "******Results for G4*************\n",
      "MSE = 354.5572223171357\n",
      "MAE = 13.926751645469794\n",
      "R^2 = -6.351079736583477\n",
      "\n",
      "WN\n",
      "******Results for WN*************\n",
      "MSE = 186.79515586053537\n",
      "MAE = 9.915837756971822\n",
      "R^2 = -6.739885306734721\n",
      "\n",
      "VX\n",
      "******Results for VX*************\n",
      "MSE = 458.8224551540517\n",
      "MAE = 16.488458509829478\n",
      "R^2 = -9.158236337787528\n",
      "\n",
      "B6\n",
      "******Results for B6*************\n",
      "MSE = 387.21580384230094\n",
      "MAE = 15.138437683168917\n",
      "R^2 = -8.073117345423842\n",
      "\n",
      "F9\n",
      "******Results for F9*************\n",
      "MSE = 454.82861404884875\n",
      "MAE = 16.726094896790062\n",
      "R^2 = -7.9666209356213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn_models_rfr = {'HA': '../data/HA_rfr.sav',\n",
    "                 'NK': '../data/NK_rfr.sav',\n",
    "                 'AA': '../data/AA_rfr.sav',\n",
    "                 'UA': '../data/UA_rfr.sav',\n",
    "                 'AS': '../data/AS_rfr.sav',\n",
    "                 'DL': '../data/DL_rfr.sav',\n",
    "                 'G4': '../data/G4_rfr.sav',\n",
    "                 'WN': '../data/WN_rfr.sav',\n",
    "                 'VX': '../data/VX_rfr.sav',\n",
    "                 'B6': '../data/B6_rfr.sav',\n",
    "                 'F9': '../data/F9_rfr.sav'}\n",
    "get_results('RandomForestRegressor')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–––––––––––––––––––Support Vector Machine Predictions–––––––––––––––––––––\n",
      "HA\n",
      "******Results for HA*************\n",
      "MSE = 127.3141459834535\n",
      "MAE = 7.604924093910531\n",
      "R^2 = -13482.238825259483\n",
      "\n",
      "NK\n",
      "******Results for NK*************\n",
      "MSE = 256.40861367556215\n",
      "MAE = 11.572942866908363\n",
      "R^2 = -225.25440511991877\n",
      "\n",
      "AA\n",
      "******Results for AA*************\n",
      "MSE = 258.0318855761492\n",
      "MAE = 11.768734634529613\n",
      "R^2 = -95.91572397843207\n",
      "\n",
      "UA\n",
      "******Results for UA*************\n",
      "MSE = 266.9858784943705\n",
      "MAE = 11.905431101786764\n",
      "R^2 = -394.35872740230747\n",
      "\n",
      "AS\n",
      "******Results for AS*************\n",
      "MSE = 247.90150345419576\n",
      "MAE = 11.46920453037563\n",
      "R^2 = -8695.292589794739\n",
      "\n",
      "DL\n",
      "******Results for DL*************\n",
      "MSE = 228.74397669067332\n",
      "MAE = 10.840668085771117\n",
      "R^2 = -272.4540780446128\n",
      "\n",
      "G4\n",
      "******Results for G4*************\n",
      "MSE = 330.63518419968267\n",
      "MAE = 13.057178583433616\n",
      "R^2 = -370.2915850944284\n",
      "\n",
      "WN\n",
      "******Results for WN*************\n",
      "MSE = 185.51835580639528\n",
      "MAE = 9.811603404493717\n",
      "R^2 = -14.639997970298833\n",
      "\n",
      "VX\n",
      "******Results for VX*************\n",
      "MSE = 432.6853662921076\n",
      "MAE = 15.891568120928191\n",
      "R^2 = -4175.252352609175\n",
      "\n",
      "B6\n",
      "******Results for B6*************\n",
      "MSE = 382.67264466525495\n",
      "MAE = 14.635963371006245\n",
      "R^2 = -108.19060670013104\n",
      "\n",
      "F9\n",
      "******Results for F9*************\n",
      "MSE = 438.71382269710466\n",
      "MAE = 15.937461726487317\n",
      "R^2 = -249.9941326918786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn_models_sav ={'HA': '../data/HA_svr.sav',\n",
    "                'NK': '../data/NK_svr.sav',\n",
    "                'AA': '../data/AA_svr.sav',\n",
    "                'UA': '../data/UA_svr.sav',\n",
    "                'AS': '../data/AS_svr.sav',\n",
    "                'DL': '../data/DL_svr.sav',\n",
    "                'G4': '../data/G4_svr.sav',\n",
    "                'WN': '../data/WN_svr.sav',\n",
    "                'VX': '../data/VX_svr.sav',\n",
    "                'B6': '../data/B6_svr.sav',\n",
    "                'F9': '../data/F9_svr.sav'}\n",
    "get_results('Support Vector Machine')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final Evalutation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "outputs": [],
   "source": [
    "test_data = reload_file(fn_test_flights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "outputs": [],
   "source": [
    "airlines = test_data['mkt_unique_carrier'].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "outputs": [],
   "source": [
    "f_test_preparation = test_datasets_preparation(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "outputs": [],
   "source": [
    "first_7_days = pd.to_datetime('2020-01-08')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "outputs": [],
   "source": [
    "f_test_preparation = f_test_preparation[f_test_preparation['crs_dep_datetime'] < first_7_days]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "outputs": [],
   "source": [
    "# (time, airline, airtime, origin, distance)\n",
    "def split(df, airlines):\n",
    "    df['departing_hour'] = df['crs_dep_datetime'].apply(lambda c:c.time())\n",
    "    df['dep_time_in_sec'] = df['departing_hour'].apply(lambda c:c.hour*3600+c.minute*60)\n",
    "    datasets = {}\n",
    "    for airline in airlines:\n",
    "        df_predict = df[['dep_time_in_sec', 'crs_elapsed_time', 'origin', 'distance']]\n",
    "        df_predict = pd.get_dummies(df_predict, ['origin'])\n",
    "        df_submit = df[['crs_dep_datetime', 'airline', 'mkt_carrier_fl_num', 'origin', 'dest']] # predicted_delay\n",
    "        datasets[airline] = df_predict, df_submit\n",
    "    return datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "outputs": [],
   "source": [
    "def pre_populate(data_predict, airlines):\n",
    "    \"\"\"Assuming Init Model seen all the columns\"\"\"\n",
    "    with open('../data/data_records.json') as f:\n",
    "        records = json.load(f)\n",
    "    dict_df = {}\n",
    "    for airline in airlines:\n",
    "        x_cur, df_submit = data_predict[airline]\n",
    "        init_col = records[airline]\n",
    "        curr_cols = x_cur.columns.to_list()\n",
    "        missing_cols = set(init_col) - set(curr_cols)\n",
    "        for col in missing_cols:\n",
    "            x_cur[col] = 0\n",
    "        x = x_cur.reindex(columns=init_col)\n",
    "        dict_df[airline] = x, df_submit\n",
    "    return dict_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "outputs": [],
   "source": [
    "def get_results(df_dict, airlines):\n",
    "    results = {}\n",
    "    for airline in airlines:\n",
    "        # load the model from disk\n",
    "        loaded_model = pickle.load(open(models[airline], 'rb'))\n",
    "        X_test, df_submit = df_dict[airline]\n",
    "        y_pred = loaded_model.predict(X_test)\n",
    "        print(f'Predicted for {airline}...')\n",
    "        df_submit['predicted_delay'] = y_pred\n",
    "        results[airline] = df_submit\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "outputs": [],
   "source": [
    "test_dicts = split(f_test_preparation, airlines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "outputs": [],
   "source": [
    "populated_df = pre_populate(test_dicts, airlines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "outputs": [],
   "source": [
    "results = get_results(populated_df, airlines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "outputs": [],
   "source": [
    "def combine_results(results_dict, airlines):\n",
    "    to_concat = [results_dict[airline] for airline in airlines]\n",
    "    return pd.concat(to_concat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "outputs": [],
   "source": [
    "df_to_submit = combine_results(results, airlines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "outputs": [
    {
     "data": {
      "text/plain": "          crs_dep_datetime airline  mkt_carrier_fl_num origin dest  \\\n0      2020-01-01 18:10:00      WN                5888    ONT  SFO   \n1      2020-01-01 11:50:00      WN                6276    ONT  SFO   \n2      2020-01-01 20:20:00      WN                4598    ONT  SJC   \n3      2020-01-01 13:40:00      WN                4761    ONT  SJC   \n4      2020-01-01 09:15:00      WN                5162    ONT  SJC   \n...                    ...     ...                 ...    ...  ...   \n150618 2020-01-07 17:55:00      DL                4813    DTW  JFK   \n150619 2020-01-07 06:00:00      DL                4814    GSP  LGA   \n150620 2020-01-07 17:15:00      DL                4815    ATL  XNA   \n150621 2020-01-07 18:51:00      DL                4815    XNA  ATL   \n150622 2020-01-07 06:00:00      DL                4816    PWM  LGA   \n\n        predicted_delay  \n0             -9.237199  \n1            -10.738094  \n2            -11.376552  \n3            -12.360735  \n4            -12.449402  \n...                 ...  \n150618        -5.795025  \n150619        -2.756883  \n150620        -3.135142  \n150621        -3.144292  \n150622        -8.490228  \n\n[1506230 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>crs_dep_datetime</th>\n      <th>airline</th>\n      <th>mkt_carrier_fl_num</th>\n      <th>origin</th>\n      <th>dest</th>\n      <th>predicted_delay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-01-01 18:10:00</td>\n      <td>WN</td>\n      <td>5888</td>\n      <td>ONT</td>\n      <td>SFO</td>\n      <td>-9.237199</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-01-01 11:50:00</td>\n      <td>WN</td>\n      <td>6276</td>\n      <td>ONT</td>\n      <td>SFO</td>\n      <td>-10.738094</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-01-01 20:20:00</td>\n      <td>WN</td>\n      <td>4598</td>\n      <td>ONT</td>\n      <td>SJC</td>\n      <td>-11.376552</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-01-01 13:40:00</td>\n      <td>WN</td>\n      <td>4761</td>\n      <td>ONT</td>\n      <td>SJC</td>\n      <td>-12.360735</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-01-01 09:15:00</td>\n      <td>WN</td>\n      <td>5162</td>\n      <td>ONT</td>\n      <td>SJC</td>\n      <td>-12.449402</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>150618</th>\n      <td>2020-01-07 17:55:00</td>\n      <td>DL</td>\n      <td>4813</td>\n      <td>DTW</td>\n      <td>JFK</td>\n      <td>-5.795025</td>\n    </tr>\n    <tr>\n      <th>150619</th>\n      <td>2020-01-07 06:00:00</td>\n      <td>DL</td>\n      <td>4814</td>\n      <td>GSP</td>\n      <td>LGA</td>\n      <td>-2.756883</td>\n    </tr>\n    <tr>\n      <th>150620</th>\n      <td>2020-01-07 17:15:00</td>\n      <td>DL</td>\n      <td>4815</td>\n      <td>ATL</td>\n      <td>XNA</td>\n      <td>-3.135142</td>\n    </tr>\n    <tr>\n      <th>150621</th>\n      <td>2020-01-07 18:51:00</td>\n      <td>DL</td>\n      <td>4815</td>\n      <td>XNA</td>\n      <td>ATL</td>\n      <td>-3.144292</td>\n    </tr>\n    <tr>\n      <th>150622</th>\n      <td>2020-01-07 06:00:00</td>\n      <td>DL</td>\n      <td>4816</td>\n      <td>PWM</td>\n      <td>LGA</td>\n      <td>-8.490228</td>\n    </tr>\n  </tbody>\n</table>\n<p>1506230 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_submit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "outputs": [],
   "source": [
    "df_to_submit.to_csv('../data/final_submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}